{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40421/2491112479.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/22 15:38:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# The SparkSession API provides a single point of entry to interact with Spark functionality,\n",
    "# including Spark SQL, DataFrames, Datasets, and other Spark features.\n",
    "spark = SparkSession.builder.appName(\"Datacamp Pyspark Tutorial\").config(\"spark.memory.offHeap.enabled\",\"true\").config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV into a Spark DataFrame\n",
    "file_name = 'online_retail.csv'\n",
    "current_directory = Path.cwd()\n",
    "file_directory = current_directory / file_name\n",
    "df = spark.read.csv(str(file_directory), header=True,escape=\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/10 8:26|2.55     |17850     |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/10 8:26|2.75     |17850     |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the top 5 rows\n",
    "df.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applies the aggration function of count and returns its value\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4373"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applies the aggration function of distinct and count and returns its value\n",
    "df.select('CustomerID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+\n",
      "|        Country|country_count|\n",
      "+---------------+-------------+\n",
      "| United Kingdom|         3950|\n",
      "|        Germany|           95|\n",
      "|         France|           87|\n",
      "|          Spain|           31|\n",
      "|        Belgium|           25|\n",
      "|    Switzerland|           21|\n",
      "|       Portugal|           19|\n",
      "|          Italy|           15|\n",
      "|        Finland|           12|\n",
      "|        Austria|           11|\n",
      "|         Norway|           10|\n",
      "|        Denmark|            9|\n",
      "|Channel Islands|            9|\n",
      "|      Australia|            9|\n",
      "|    Netherlands|            9|\n",
      "|         Sweden|            8|\n",
      "|         Cyprus|            8|\n",
      "|          Japan|            8|\n",
      "|         Poland|            6|\n",
      "|         Greece|            4|\n",
      "+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the which countries made the most purchases, order resultsin descending order\n",
    "df.groupBy('Country').agg(countDistinct('CustomerID').alias('country_count')).orderBy(desc('country_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          max(date)|\n",
      "+-------------------+\n",
      "|2012-12-10 16:21:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the most recent purchase\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "df = df.withColumn('date',to_timestamp(\"InvoiceDate\", 'yy/MM/dd HH:mm'))\n",
    "df.select(max(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, this code snippet is used to convert a string column to a timestamp format\n",
    "# and calculate the time difference between two columns in a PySpark DataFrame.\n",
    "\n",
    "# creates a new column called \"from_date\" in the PySpark DataFrame \"df\"\n",
    "# and sets all values in this column to the string \"12/1/10 08:26\".\n",
    "df = df.withColumn(\"from_date\", lit(\"12/1/10 08:26\"))\n",
    "# converts the \"from_date\" column from a string to a timestamp format using the \"to_timestamp\" function.\n",
    "df = df.withColumn('from_date',to_timestamp(\"from_date\", 'yy/MM/dd HH:mm'))\n",
    "# creates a new DataFrame called \"df2\" by applying two transformations to the original DataFrame \"df\"\n",
    "df2=df.withColumn('from_date',to_timestamp(col('from_date'))).withColumn('recency',col(\"date\").cast(\"long\") - col('from_date').cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.join(df2.groupBy('CustomerID').agg(max('recency').alias('recency')),on='recency',how='leftsemi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+----------------------------------+--------+------------+---------+----------+--------------+-------------------+-------------------+\n",
      "|recency|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate |UnitPrice|CustomerID|Country       |date               |from_date          |\n",
      "+-------+---------+---------+----------------------------------+--------+------------+---------+----------+--------------+-------------------+-------------------+\n",
      "|540    |536369   |21756    |BATH BUILDING BLOCK WORD          |3       |12/1/10 8:35|5.95     |13047     |United Kingdom|2012-01-10 08:35:00|2012-01-10 08:26:00|\n",
      "|2040   |536371   |22086    |PAPER CHAIN KIT 50'S CHRISTMAS    |80      |12/1/10 9:00|2.55     |13748     |United Kingdom|2012-01-10 09:00:00|2012-01-10 08:26:00|\n",
      "|3960   |536375   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |12/1/10 9:32|2.55     |17850     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|\n",
      "|3960   |536375   |71053    |WHITE METAL LANTERN               |6       |12/1/10 9:32|3.39     |17850     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|\n",
      "|3960   |536375   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |12/1/10 9:32|2.75     |17850     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|\n",
      "+-------+---------+---------+----------------------------------+--------+------------+---------+----------+--------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the top 5 rows\n",
    "df2.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- recency: long (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- from_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view all the variablespresent in a PySpark dataframe is to use its printSchema() function.\n",
    "# This is the equivalent of the info() function in Pandas\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s now calculate the value of frequency - how often a customer bought something on the platform. \n",
    "# To do this, we just need to group by each customer ID and count the number of items they purchased\n",
    "df_freq = df2.groupBy('CustomerID').agg(count('InvoiceDate').alias('frequency'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|frequency|\n",
      "+----------+---------+\n",
      "|16250     |14       |\n",
      "|15574     |121      |\n",
      "|15271     |24       |\n",
      "|15555     |37       |\n",
      "|17757     |49       |\n",
      "+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show top 5 rows from the frequency DataFrame\n",
    "df_freq.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join df2 DataFrame with df_freq DataFrame on key 'CustomerID'\n",
    "df3 = df2.join(df_freq,on='CustomerID',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- recency: long (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- from_date: timestamp (nullable = true)\n",
      " |-- frequency: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema to show we joined the DataFrames successfully\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+\n",
      "|CustomerID|recency|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate |UnitPrice|Country       |date               |from_date          |frequency|\n",
      "+----------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+\n",
      "|13047     |540    |536369   |21756    |BATH BUILDING BLOCK WORD          |3       |12/1/10 8:35|5.95     |United Kingdom|2012-01-10 08:35:00|2012-01-10 08:26:00|1        |\n",
      "|13748     |2040   |536371   |22086    |PAPER CHAIN KIT 50'S CHRISTMAS    |80      |12/1/10 9:00|2.55     |United Kingdom|2012-01-10 09:00:00|2012-01-10 08:26:00|1        |\n",
      "|17850     |3960   |536375   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |12/1/10 9:32|2.55     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |\n",
      "|17850     |3960   |536375   |71053    |WHITE METAL LANTERN               |6       |12/1/10 9:32|3.39     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |\n",
      "|17850     |3960   |536375   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |12/1/10 9:32|2.75     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |\n",
      "+----------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the top 5 rows of df3 DataFrame\n",
    "df3.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monetary value spent by each customer\n",
    "# we create a new column in our m_val DataFrame as the output of multiplying Quantity and UnitePrice from df3 DataFrame\n",
    "m_val = df3.withColumn('TotalAmount',col(\"Quantity\") * col(\"UnitPrice\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- recency: long (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- from_date: timestamp (nullable = true)\n",
      " |-- frequency: long (nullable = false)\n",
      " |-- TotalAmount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the top 5 rows of df3 DataFrame\n",
    "m_val.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+------------------+\n",
      "|CustomerID|recency|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate |UnitPrice|Country       |date               |from_date          |frequency|TotalAmount       |\n",
      "+----------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+------------------+\n",
      "|13047     |540    |536369   |21756    |BATH BUILDING BLOCK WORD          |3       |12/1/10 8:35|5.95     |United Kingdom|2012-01-10 08:35:00|2012-01-10 08:26:00|1        |17.85             |\n",
      "|13748     |2040   |536371   |22086    |PAPER CHAIN KIT 50'S CHRISTMAS    |80      |12/1/10 9:00|2.55     |United Kingdom|2012-01-10 09:00:00|2012-01-10 08:26:00|1        |204.0             |\n",
      "|17850     |3960   |536375   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |12/1/10 9:32|2.55     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |15.299999999999999|\n",
      "|17850     |3960   |536375   |71053    |WHITE METAL LANTERN               |6       |12/1/10 9:32|3.39     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |20.34             |\n",
      "|17850     |3960   |536375   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |12/1/10 9:32|2.75     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |22.0              |\n",
      "+----------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the newly created TotalAmount column based on quantity and unit price\n",
    "m_val.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the total amount spent by each customer overall, we just need to group by the CustomerID column and sum the total amount spent\n",
    "m_val = m_val.groupBy('CustomerID').agg(sum('TotalAmount').alias('monetary_value'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- monetary_value: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of m_val DataFrame\n",
    "m_val.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|CustomerID|monetary_value   |\n",
      "+----------+-----------------+\n",
      "|16250     |226.14           |\n",
      "|15574     |375.65           |\n",
      "|15271     |111.75           |\n",
      "|15555     |620.3499999999998|\n",
      "|17757     |385.25           |\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/22 15:39:01 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# show the top 5 rows of m_val DataFrame\n",
    "m_val.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge this DataFrame with all the other variables\n",
    "finaldf = m_val.join(df3,on='CustomerID',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- monetary_value: double (nullable = true)\n",
      " |-- recency: long (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- from_date: timestamp (nullable = true)\n",
      " |-- frequency: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of finaldf DataFrame\n",
    "finaldf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+\n",
      "|CustomerID|monetary_value|recency|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate |UnitPrice|Country       |date               |from_date          |frequency|\n",
      "+----------+--------------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+\n",
      "|13047     |17.85         |540    |536369   |21756    |BATH BUILDING BLOCK WORD          |3       |12/1/10 8:35|5.95     |United Kingdom|2012-01-10 08:35:00|2012-01-10 08:26:00|1        |\n",
      "|13748     |204.0         |2040   |536371   |22086    |PAPER CHAIN KIT 50'S CHRISTMAS    |80      |12/1/10 9:00|2.55     |United Kingdom|2012-01-10 09:00:00|2012-01-10 08:26:00|1        |\n",
      "|17850     |533.22        |3960   |536375   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |12/1/10 9:32|2.55     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |\n",
      "|17850     |533.22        |3960   |536375   |71053    |WHITE METAL LANTERN               |6       |12/1/10 9:32|3.39     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |\n",
      "|17850     |533.22        |3960   |536375   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |12/1/10 9:32|2.75     |United Kingdom|2012-01-10 09:32:00|2012-01-10 08:26:00|35       |\n",
      "+----------+--------------+-------+---------+---------+----------------------------------+--------+------------+---------+--------------+-------------------+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of finaldf DataFrame\n",
    "finaldf.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have all the necessary variables needed for our machhine learning model\n",
    "# select only the required columns and drop duplicate rows from the dataframe\n",
    "finaldf = finaldf.select(['recency','frequency','monetary_value','CustomerID']).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- recency: long (nullable = true)\n",
      " |-- frequency: long (nullable = false)\n",
      " |-- monetary_value: double (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of finaldf DataFrame\n",
    "finaldf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------------+----------+\n",
      "|recency |frequency|monetary_value   |CustomerID|\n",
      "+--------+---------+-----------------+----------+\n",
      "|5580    |14       |226.14           |16250     |\n",
      "|2704800 |121      |375.65           |15574     |\n",
      "|21097260|24       |111.75           |15271     |\n",
      "|21108420|37       |620.3499999999998|15555     |\n",
      "|23699400|49       |385.25           |17757     |\n",
      "+--------+---------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of finaldf DataFrame\n",
    "finaldf.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before building the customer segmentation model, let’s standardize the dataframe\n",
    "# to ensure that all the variables are around the same scale\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "assemble=VectorAssembler(inputCols=[\n",
    "    'recency','frequency','monetary_value'\n",
    "], outputCol='features')\n",
    "\n",
    "assembled_data=assemble.transform(finaldf)\n",
    "\n",
    "scale=StandardScaler(inputCol='features',outputCol='standardized')\n",
    "data_scale=scale.fit(assembled_data)\n",
    "data_scale_output=data_scale.transform(assembled_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
